{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab2441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Title        Artist\n",
       "0       Lovin On Me   Jack Harlow\n",
       "1      Lose Control   Teddy Swims\n",
       "2  Beautiful Things  Benson Boone\n",
       "3      Cruel Summer  Taylor Swift\n",
       "4            Snooze           SZA"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the URL\n",
    "url = \"https://www.popvortex.com/music/charts/top-100-songs.php\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all p tags with class 'title-artist'\n",
    "title_artist_tags = soup.find_all('p', class_='title-artist')\n",
    "\n",
    "# Extract titles and artists from the tags\n",
    "titles = []\n",
    "artists = []\n",
    "for tag in title_artist_tags:\n",
    "    title = tag.find('cite', class_='title').text.strip()\n",
    "    artist = tag.find('em', class_='artist').text.strip()\n",
    "    titles.append(title)\n",
    "    artists.append(artist)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'Title': titles, 'Artist': artists}\n",
    "itunes_df = pd.DataFrame(data)\n",
    "\n",
    "# df.to_csv('music_chart_data.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "itunes_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c944b52a",
   "metadata": {},
   "source": [
    "# Lab 2 expand data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a318d3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Standing Next To You</td>\n",
       "      <td>Jung Kook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Perro Negro</td>\n",
       "      <td>Bad Bunny &amp; Feid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Mmhmm</td>\n",
       "      <td>BigXthaPlug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Oklahoma Smokeshow</td>\n",
       "      <td>Zach Bryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>My Eyes</td>\n",
       "      <td>Travis Scott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Coal</td>\n",
       "      <td>Dylan Gossett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>A Cold Sunday</td>\n",
       "      <td>Lil Yachty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>All Of Me</td>\n",
       "      <td>21 Savage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>N.H.I.E.</td>\n",
       "      <td>21 Savage &amp; Doja Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Should've Wore A Bonnet</td>\n",
       "      <td>21 Savage &amp; Brent Faiyaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Que Onda</td>\n",
       "      <td>Calle 24 x Chino Pacas x Fuerza Regida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Wondering Why</td>\n",
       "      <td>The Red Clay Strays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Y Lloro</td>\n",
       "      <td>Junior H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Sensational</td>\n",
       "      <td>Chris Brown Featuring Davido &amp; Lojay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Wildflowers And Wild Horses</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Worth It</td>\n",
       "      <td>Offset &amp; Don Toliver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Northern Attitude</td>\n",
       "      <td>Noah Kahan With Hozier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Scared To Start</td>\n",
       "      <td>Michael Marcagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>First Love</td>\n",
       "      <td>Oscar Ortiz X Edgardo Nunez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Where It Ends</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title                                  Artist\n",
       "80         Standing Next To You                               Jung Kook\n",
       "81                  Perro Negro                        Bad Bunny & Feid\n",
       "82                        Mmhmm                             BigXthaPlug\n",
       "83           Oklahoma Smokeshow                              Zach Bryan\n",
       "84                      My Eyes                            Travis Scott\n",
       "85                         Coal                           Dylan Gossett\n",
       "86                A Cold Sunday                              Lil Yachty\n",
       "87                    All Of Me                               21 Savage\n",
       "88                     N.H.I.E.                    21 Savage & Doja Cat\n",
       "89      Should've Wore A Bonnet                21 Savage & Brent Faiyaz\n",
       "90                     Que Onda  Calle 24 x Chino Pacas x Fuerza Regida\n",
       "91                Wondering Why                     The Red Clay Strays\n",
       "92                      Y Lloro                                Junior H\n",
       "93                  Sensational    Chris Brown Featuring Davido & Lojay\n",
       "94  Wildflowers And Wild Horses                           Lainey Wilson\n",
       "95                     Worth It                    Offset & Don Toliver\n",
       "96            Northern Attitude                  Noah Kahan With Hozier\n",
       "97              Scared To Start                         Michael Marcagi\n",
       "98                   First Love             Oscar Ortiz X Edgardo Nunez\n",
       "99                Where It Ends                        Bailey Zimmerman"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the URL\n",
    "url = \"https://www.billboard.com/charts/hot-100/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all list items with class 'o-chart-results-list__item'\n",
    "song_items = soup.find_all('li', class_='o-chart-results-list__item')\n",
    "\n",
    "# Extract titles and artists from the list items\n",
    "data = {'Title': [], 'Artist': []}\n",
    "for item in song_items:\n",
    "    title_elem = item.find('h3', class_='c-title')\n",
    "    artist_elem = item.find('span', class_='c-label')\n",
    "    if title_elem and artist_elem:\n",
    "        title = title_elem.text.strip()\n",
    "        artist = artist_elem.text.strip()\n",
    "        data['Title'].append(title)\n",
    "        data['Artist'].append(artist)\n",
    "\n",
    "# Create a DataFrame\n",
    "billboard_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "billboard_df.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0045ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Title                       Artist\n",
      "0             TEXAS HOLD 'EM                      Beyoncé\n",
      "1               Lose Control                  Teddy Swims\n",
      "2           Beautiful Things                 Benson Boone\n",
      "3                    Flowers                  Miley Cyrus\n",
      "4    Turn the Lights Back On                   Billy Joel\n",
      "..                       ...                          ...\n",
      "195                 Worth It         Offset & Don Toliver\n",
      "196        Northern Attitude       Noah Kahan With Hozier\n",
      "197          Scared To Start              Michael Marcagi\n",
      "198               First Love  Oscar Ortiz X Edgardo Nunez\n",
      "199            Where It Ends             Bailey Zimmerman\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate both DataFrames vertically\n",
    "combined_df = pd.concat([itunes_df, billboard_df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf32615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged DataFrame to a CSV file\n",
    "combined_df.to_csv('combined_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6091b2db",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc45f9",
   "metadata": {},
   "source": [
    "A list with the different kind of datasets available in data.gov.uk: url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c21569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Business and economy\n",
      "Description: Small businesses, industry, imports, exports and trade\n",
      "\n",
      "Topic: Crime and justice\n",
      "Description: Courts, police, prison, offenders, borders and immigration\n",
      "\n",
      "Topic: Defence\n",
      "Description: Armed forces, health and safety, search and rescue\n",
      "\n",
      "Topic: Education\n",
      "Description: Students, training, qualifications and the National Curriculum\n",
      "\n",
      "Topic: Environment\n",
      "Description: Weather, flooding, rivers, air quality, geology and agriculture\n",
      "\n",
      "Topic: Government\n",
      "Description: Staff numbers and pay, local councillors and department business plans\n",
      "\n",
      "Topic: Government spending\n",
      "Description: Includes all payments by government departments over £25,000\n",
      "\n",
      "Topic: Health\n",
      "Description: Includes smoking, drugs, alcohol, medicine performance and hospitals\n",
      "\n",
      "Topic: Mapping\n",
      "Description: Addresses, boundaries, land ownership, aerial photographs, seabed and land terrain\n",
      "\n",
      "Topic: Society\n",
      "Description: Employment, benefits, household finances, poverty and population\n",
      "\n",
      "Topic: Towns and cities\n",
      "Description: Includes housing, urban planning, leisure, waste and energy, consumption\n",
      "\n",
      "Topic: Transport\n",
      "Description: Airports, roads, freight, electric vehicles, parking, buses and footpaths\n",
      "\n",
      "Topic: Digital service performance\n",
      "Description: Cost, usage, completion rate, digital take-up, satisfaction\n",
      "\n",
      "Topic: Government reference data\n",
      "Description: Trusted data that is referenced and shared across government departments\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the URL\n",
    "url = \"https://www.data.gov.uk/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the unordered list with class 'govuk-list dgu-topics__list'\n",
    "ul = soup.find('ul', class_='govuk-list dgu-topics__list')\n",
    "\n",
    "# Extract all list items from the unordered list\n",
    "dataset_topics = ul.find_all('li')\n",
    "\n",
    "# Iterate through each list item and print the topic and description\n",
    "for topic in dataset_topics:\n",
    "    topic_name = topic.find('h3', class_='govuk-heading-s dgu-topics__heading').text.strip()\n",
    "    description = topic.find('p', class_='govuk-body').text.strip()\n",
    "    print(\"Topic:\", topic_name)\n",
    "    print(\"Description:\", description)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815f69b",
   "metadata": {},
   "source": [
    "Display the top 10 languages by number of native speakers stored in a pandas dataframe: url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2566ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language Native Speakers (in millions)\n",
      "0        1              Mandarin Chinese\n",
      "1        2                       Spanish\n",
      "2        3                       English\n",
      "3        3                        Arabic\n",
      "4        5                         Hindi\n",
      "5        6                       Bengali\n",
      "6        7                    Portuguese\n",
      "7        8                       Russian\n",
      "8        9                      Japanese\n",
      "9       10               Western Punjabi\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table with class 'wikitable sortable'\n",
    "table = soup.find('table', class_='wikitable sortable')\n",
    "\n",
    "# Extract the rows from the table\n",
    "rows = table.find_all('tr')[1:11]  # Skip the header row, take only top 10 languages\n",
    "\n",
    "# Initialize lists to store language data\n",
    "languages = []\n",
    "native_speakers = []\n",
    "\n",
    "# Iterate through each row and extract language data\n",
    "for row in rows:\n",
    "    columns = row.find_all('td')\n",
    "    language = columns[0].text.strip()\n",
    "    speakers = columns[1].text.strip()\n",
    "    languages.append(language)\n",
    "    native_speakers.append(speakers)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "data = {'Language': languages, 'Native Speakers (in millions)': native_speakers}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2dfdfe",
   "metadata": {},
   "source": [
    "Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: url ='https://en.wikipedia.org/wiki/Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db36d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://en.wiktionary.org/wiki/Python', 'https://en.wiktionary.org/wiki/python', '/w/index.php?title=Python&action=edit&section=1', '/wiki/Pythonidae', '/wiki/Python_(genus)', '/wiki/Python_(mythology)', '/w/index.php?title=Python&action=edit&section=2', '/wiki/Python_(programming_language)', '/wiki/CMU_Common_Lisp', '/wiki/PERQ#PERQ_3', '/w/index.php?title=Python&action=edit&section=3', '/wiki/Python_of_Aenus', '/wiki/Python_(painter)', '/wiki/Python_of_Byzantium', '/wiki/Python_of_Catana', '/wiki/Python_Anghelo', '/w/index.php?title=Python&action=edit&section=4', '/wiki/Python_(Efteling)', '/wiki/Python_(Busch_Gardens_Tampa_Bay)', '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)', '/w/index.php?title=Python&action=edit&section=5', '/wiki/Python_(automobile_maker)', '/wiki/Python_(Ford_prototype)', '/w/index.php?title=Python&action=edit&section=6', '/wiki/Python_(missile)', '/wiki/Python_(nuclear_primary)', '/wiki/Colt_Python', '/w/index.php?title=Python&action=edit&section=7', '/wiki/Python_(codename)', '/wiki/Python_(film)', '/wiki/Monty_Python', '/wiki/Python_(Monty)_Pictures', '/wiki/Timon_of_Phlius', '/w/index.php?title=Python&action=edit&section=8', '/wiki/Pyton', '/wiki/Pithon', '/wiki/File:Disambig_gray.svg', '/wiki/Help:Disambiguation', 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0', 'https://en.wikipedia.org/w/index.php?title=Python&oldid=1196720317']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page on Python\n",
    "url = 'https://en.wikipedia.org/wiki/Python'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the div element with id=\"mw-content-text\"\n",
    "    content_div = soup.find('div', id='mw-content-text')\n",
    "    \n",
    "    # Initialize a list to store links\n",
    "    links = []\n",
    "    \n",
    "    # Find all <a> tags within the content_div\n",
    "    for link in content_div.find_all('a', href=True):\n",
    "        links.append(link['href'])\n",
    "    \n",
    "    # Display the list of links\n",
    "    print(links)\n",
    "else:\n",
    "    print('Failed to retrieve data from the website')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f9648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
